{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndsX_NnBjkrz",
        "outputId": "b2403a02-0975-40c2-d11b-c2b43e10e6b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=b22b0a50c8b913231be7bbb6b91194bfe39fd8f83ad48ffd61f53f0d383e90e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Initialize SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        ".appName(\"PySpark DataFrame Example\") \\\n",
        ".getOrCreate()\n",
        "\n",
        "# Sample data representing employees\n",
        "\n",
        "data = [\n",
        "\n",
        "    (\"John Doe\", \"Engineering\", 75000),\n",
        "\n",
        "    (\"Jane Smith\", \"Marketing\", 60000),\n",
        "\n",
        "    (\"Sam Brown\", \"Engineering\", 80000),\n",
        "\n",
        "    (\"Emily Davis\", \"HR\", 50000),\n",
        "\n",
        "    (\"Michael Johnson\", \"Marketing\", 70000),\n",
        "\n",
        "]\n",
        "\n",
        "# Define schema for DataFrame\n",
        "\n",
        "columns = [\"Name\", \"Department\", \"Salary\"]\n",
        "\n",
        "# Create DataFrame\n",
        "\n",
        "df = spark.createDataFrame(data, schema=columns)\n",
        "\n",
        "# Show the DataFrame\n",
        "\n",
        "df.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7WZRXankHOe",
        "outputId": "4415f61d-109e-458f-8775-59e3dcd0605f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-----------+------+\n",
            "|           Name| Department|Salary|\n",
            "+---------------+-----------+------+\n",
            "|       John Doe|Engineering| 75000|\n",
            "|     Jane Smith|  Marketing| 60000|\n",
            "|      Sam Brown|Engineering| 80000|\n",
            "|    Emily Davis|         HR| 50000|\n",
            "|Michael Johnson|  Marketing| 70000|\n",
            "+---------------+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter: Select employees with a salary greater than 65,000\n",
        "high_salary_df = df.filter(col(\"Salary\") > 65000)\n",
        "print(\"Employees with Salary > 65,000:\")\n",
        "# Show the filtered DataFrame\n",
        "high_salary_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehpWz3__qRR2",
        "outputId": "6fcced8c-b856-484e-8b76-61616eaa1d86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Employees with Salary > 65,000:\n",
            "+---------------+-----------+------+\n",
            "|           Name| Department|Salary|\n",
            "+---------------+-----------+------+\n",
            "|       John Doe|Engineering| 75000|\n",
            "|      Sam Brown|Engineering| 80000|\n",
            "|Michael Johnson|  Marketing| 70000|\n",
            "+---------------+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by Department and Calculate the average salary\n",
        "avg_salary_by_df = df.groupBy(\"Department\").avg(\"Salary\")\n",
        "print(\"Average Salary by Department:\")\n",
        "# Show the average salary by department\n",
        "avg_salary_by_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfJ6ZVpArCuR",
        "outputId": "4d644f7f-f611-4f14-d523-9dfd7a9d0193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Salary by Department:\n",
            "+-----------+-----------+\n",
            "| Department|avg(Salary)|\n",
            "+-----------+-----------+\n",
            "|Engineering|    77500.0|\n",
            "|  Marketing|    65000.0|\n",
            "|         HR|    50000.0|\n",
            "+-----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Customer Transaction Analysis\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Sample data for customers\n",
        "customers = [\n",
        "    (1, \"Ravi\", \"Mumbai\"),\n",
        "    (2, \"Priya\", \"Delhi\"),\n",
        "    (3, \"Vijay\", \"Bangalore\"),\n",
        "    (4, \"Anita\", \"Chennai\"),\n",
        "    (5, \"Raj\", \"Hyderabad\"),\n",
        "]\n",
        "\n",
        "# Sample data for transactions\n",
        "transactions = [\n",
        "    (1, 1, 10000.50),\n",
        "    (2, 2, 20000.75),\n",
        "    (3, 1, 15000.25),\n",
        "    (4, 3, 30000.00),\n",
        "    (5, 2, 40000.50),\n",
        "    (6, 4, 25000.00),\n",
        "    (7, 5, 18000.75),\n",
        "    (8, 1, 5000.00),\n",
        "]\n",
        "\n",
        "# Define schema for DataFrames\n",
        "customer_columns = [\"customer_id\", \"Name\", \"city\"]\n",
        "transaction_columns = [\"Transaction_id\", \"customer_id\", \"Amount\"]  # Changed CustomerId to customer_id\n",
        "\n",
        "# Create DataFrames\n",
        "customer_df = spark.createDataFrame(customers, schema=customer_columns)\n",
        "transactions_df = spark.createDataFrame(transactions, schema=transaction_columns)\n",
        "\n",
        "# Show the DataFrames\n",
        "print(\"Customers DataFrame:\")\n",
        "customer_df.show()\n",
        "\n",
        "print(\"Transactions DataFrame:\")\n",
        "transactions_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DKP07IxBMfG",
        "outputId": "e5a27045-3226-43f8-9cb1-f01302d9cdf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customers DataFrame:\n",
            "+-----------+-----+---------+\n",
            "|customer_id| Name|     city|\n",
            "+-----------+-----+---------+\n",
            "|          1| Ravi|   Mumbai|\n",
            "|          2|Priya|    Delhi|\n",
            "|          3|Vijay|Bangalore|\n",
            "|          4|Anita|  Chennai|\n",
            "|          5|  Raj|Hyderabad|\n",
            "+-----------+-----+---------+\n",
            "\n",
            "Transactions DataFrame:\n",
            "+--------------+-----------+--------+\n",
            "|Transaction_id|customer_id|  Amount|\n",
            "+--------------+-----------+--------+\n",
            "|             1|          1| 10000.5|\n",
            "|             2|          2|20000.75|\n",
            "|             3|          1|15000.25|\n",
            "|             4|          3| 30000.0|\n",
            "|             5|          2| 40000.5|\n",
            "|             6|          4| 25000.0|\n",
            "|             7|          5|18000.75|\n",
            "|             8|          1|  5000.0|\n",
            "+--------------+-----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Join the DataFrames on customer_id\n",
        "customer_transactions_df = customer_df.join(transactions_df, on=\"customer_id\")\n",
        "print(\"Customer Transactions DataFrame:\")\n",
        "customer_transactions_df.show()\n",
        "\n",
        "# Calculate the total amount spent by each customer\n",
        "total_spent_df = customer_transactions_df.groupBy(\"Name\").sum(\"Amount\").withColumnRenamed(\"sum(Amount)\", \"TotalSpent\")\n",
        "print(\"Total Amount Spent by Each Customer:\")\n",
        "total_spent_df.show()\n",
        "\n",
        "# Find customers who have spent more than 30000\n",
        "big_spender_df = total_spent_df.filter(col(\"TotalSpent\") > 30000)\n",
        "print(\"Customers who have spent more than 30000:\")\n",
        "big_spender_df.show()\n",
        "\n",
        "# Count the number of transactions per customer\n",
        "transaction_count_df = customer_transactions_df.groupBy(\"Name\").count().withColumnRenamed(\"count\", \"TransactionCount\")\n",
        "print(\"Number of Transactions per Customer:\")\n",
        "transaction_count_df.show()\n",
        "\n",
        "# Sort customers by total amount spent in descending order\n",
        "sorted_spenders_df = total_spent_df.orderBy(col(\"TotalSpent\").desc())\n",
        "print(\"Customers Sorted by Total Amount Spent:\")\n",
        "sorted_spenders_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeTrqbPHJCyy",
        "outputId": "9804dcc5-f81d-4337-e04d-2587f50f99a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customer Transactions DataFrame:\n",
            "+-----------+-----+---------+--------------+--------+\n",
            "|customer_id| Name|     city|Transaction_id|  Amount|\n",
            "+-----------+-----+---------+--------------+--------+\n",
            "|          1| Ravi|   Mumbai|             1| 10000.5|\n",
            "|          1| Ravi|   Mumbai|             3|15000.25|\n",
            "|          1| Ravi|   Mumbai|             8|  5000.0|\n",
            "|          2|Priya|    Delhi|             2|20000.75|\n",
            "|          2|Priya|    Delhi|             5| 40000.5|\n",
            "|          3|Vijay|Bangalore|             4| 30000.0|\n",
            "|          4|Anita|  Chennai|             6| 25000.0|\n",
            "|          5|  Raj|Hyderabad|             7|18000.75|\n",
            "+-----------+-----+---------+--------------+--------+\n",
            "\n",
            "Total Amount Spent by Each Customer:\n",
            "+-----+----------+\n",
            "| Name|TotalSpent|\n",
            "+-----+----------+\n",
            "| Ravi|  30000.75|\n",
            "|Priya|  60001.25|\n",
            "|Vijay|   30000.0|\n",
            "|Anita|   25000.0|\n",
            "|  Raj|  18000.75|\n",
            "+-----+----------+\n",
            "\n",
            "Customers who have spent more than 30000:\n",
            "+-----+----------+\n",
            "| Name|TotalSpent|\n",
            "+-----+----------+\n",
            "| Ravi|  30000.75|\n",
            "|Priya|  60001.25|\n",
            "+-----+----------+\n",
            "\n",
            "Number of Transactions per Customer:\n",
            "+-----+----------------+\n",
            "| Name|TransactionCount|\n",
            "+-----+----------------+\n",
            "| Ravi|               3|\n",
            "|Priya|               2|\n",
            "|Vijay|               1|\n",
            "|Anita|               1|\n",
            "|  Raj|               1|\n",
            "+-----+----------------+\n",
            "\n",
            "Customers Sorted by Total Amount Spent:\n",
            "+-----+----------+\n",
            "| Name|TotalSpent|\n",
            "+-----+----------+\n",
            "|Priya|  60001.25|\n",
            "| Ravi|  30000.75|\n",
            "|Vijay|   30000.0|\n",
            "|Anita|   25000.0|\n",
            "|  Raj|  18000.75|\n",
            "+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cjkmvufhZOGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ### **Exercise: Product Sales Analysis**\n",
        "\n",
        "# #### **Step 1: Create DataFrames**\n",
        "\n",
        "# You will create two DataFrames: one for products and another for sales transactions. Then, you’ll perform operations like joining these DataFrames and analyzing the data.\n",
        "\n",
        "# ```python\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Product Sales Analysis\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Sample data for products\n",
        "products = [\n",
        "    (1, \"Laptop\", \"Electronics\", 50000),\n",
        "    (2, \"Smartphone\", \"Electronics\", 30000),\n",
        "    (3, \"Table\", \"Furniture\", 15000),\n",
        "    (4, \"Chair\", \"Furniture\", 5000),\n",
        "    (5, \"Headphones\", \"Electronics\", 2000),\n",
        "]\n",
        "\n",
        "# Sample data for sales transactions\n",
        "sales = [\n",
        "    (1, 1, 2),\n",
        "    (2, 2, 1),\n",
        "    (3, 3, 3),\n",
        "    (4, 1, 1),\n",
        "    (5, 4, 5),\n",
        "    (6, 2, 2),\n",
        "    (7, 5, 10),\n",
        "    (8, 3, 1),\n",
        "]\n",
        "\n",
        "# Define schema for DataFrames\n",
        "product_columns = [\"ProductID\", \"ProductName\", \"Category\", \"Price\"]\n",
        "sales_columns = [\"SaleID\", \"ProductID\", \"Quantity\"]\n",
        "\n",
        "# Create DataFrames\n",
        "product_df = spark.createDataFrame(products, schema=product_columns)\n",
        "sales_df = spark.createDataFrame(sales, schema=sales_columns)\n",
        "\n",
        "# Show the DataFrames\n",
        "print(\"Products DataFrame:\")\n",
        "product_df.show()\n",
        "\n",
        "print(\"Sales DataFrame:\")\n",
        "sales_df.show()\n",
        "# ```\n",
        "\n",
        "# #### **Step 2: Perform the Following Tasks**\n",
        "\n",
        "# 1. **Join the DataFrames:**\n",
        "#    - Join the `product_df` and `sales_df` DataFrames on `ProductID` to create a combined DataFrame with product and sales data.\n",
        "product_and_sales_df = product_df.join(sales_df, on=\"ProductID\")\n",
        "print(\"Product and Sales DataFrame:\")\n",
        "product_and_sales_df.show()\n",
        "\n",
        "# 2. **Calculate Total Sales Value:**\n",
        "#    - For each product, calculate the total sales value by multiplying the price by the quantity sold.\n",
        "total_sales_df = product_and_sales_df.withColumn(\"TotalSales\", col(\"Price\") * col(\"Quantity\"))\n",
        "print(\"Total Sales DataFrame:\")\n",
        "total_sales_df.show()\n",
        "\n",
        "# 3. **Find the Total Sales for Each Product Category:**\n",
        "#    - Group the data by the `Category` column and calculate the total sales value for each product category.\n",
        "total_sales_by_category_df = total_sales_df.groupBy(\"Category\").sum(\"TotalSales\").withColumnRenamed(\"sum(TotalSales)\", \"TotalSalesCategory\")\n",
        "print(\"Total Sales by Product Category:\")\n",
        "total_sales_by_category_df.show()\n",
        "\n",
        "# 4. **Identify the Top-Selling Product:**\n",
        "#    - Find the product that generated the highest total sales value.\n",
        "top_selling_product_df = total_sales_df.groupBy(\"ProductName\").sum(\"TotalSales\").withColumnRenamed(\"sum(TotalSales)\", \"TotalSalesProduct\")\n",
        "top_selling_product_df\n",
        "\n",
        "# 5. **Sort the Products by Total Sales Value:**\n",
        "#    - Sort the products by total sales value in descending order.\n",
        "sorted_products_df = top_selling_product_df.orderBy(col(\"TotalSalesProduct\").desc())\n",
        "print(\"Sorted Products by Total Sales Value:\")\n",
        "sorted_products_df.show()\n",
        "\n",
        "# 6. **Count the Number of Sales for Each Product:**\n",
        "#    - Count the number of sales transactions for each product.\n",
        "sales_count_df = total_sales_df.groupBy(\"ProductName\").count().withColumnRenamed(\"count\", \"SalesCount\")\n",
        "print(\"Number of Sales for Each Product:\")\n",
        "sales_count_df.show()\n",
        "\n",
        "# 7. **Filter the Products with Total Sales Value Greater Than ₹50,000:**\n",
        "#    - Filter out the products that have a total sales value greater than ₹50,000.\n",
        "high_value_products_df = total_sales_df.filter(col(\"TotalSales\") > 50000)\n",
        "print(\"Products with Total Sales Value Greater Than ₹50,000:\")\n",
        "high_value_products_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2VRd67CRdMu",
        "outputId": "f5409ca8-720c-4ef2-fb2e-851defa196c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Products DataFrame:\n",
            "+---------+-----------+-----------+-----+\n",
            "|ProductID|ProductName|   Category|Price|\n",
            "+---------+-----------+-----------+-----+\n",
            "|        1|     Laptop|Electronics|50000|\n",
            "|        2| Smartphone|Electronics|30000|\n",
            "|        3|      Table|  Furniture|15000|\n",
            "|        4|      Chair|  Furniture| 5000|\n",
            "|        5| Headphones|Electronics| 2000|\n",
            "+---------+-----------+-----------+-----+\n",
            "\n",
            "Sales DataFrame:\n",
            "+------+---------+--------+\n",
            "|SaleID|ProductID|Quantity|\n",
            "+------+---------+--------+\n",
            "|     1|        1|       2|\n",
            "|     2|        2|       1|\n",
            "|     3|        3|       3|\n",
            "|     4|        1|       1|\n",
            "|     5|        4|       5|\n",
            "|     6|        2|       2|\n",
            "|     7|        5|      10|\n",
            "|     8|        3|       1|\n",
            "+------+---------+--------+\n",
            "\n",
            "Product and Sales DataFrame:\n",
            "+---------+-----------+-----------+-----+------+--------+\n",
            "|ProductID|ProductName|   Category|Price|SaleID|Quantity|\n",
            "+---------+-----------+-----------+-----+------+--------+\n",
            "|        1|     Laptop|Electronics|50000|     1|       2|\n",
            "|        1|     Laptop|Electronics|50000|     4|       1|\n",
            "|        2| Smartphone|Electronics|30000|     2|       1|\n",
            "|        2| Smartphone|Electronics|30000|     6|       2|\n",
            "|        3|      Table|  Furniture|15000|     3|       3|\n",
            "|        3|      Table|  Furniture|15000|     8|       1|\n",
            "|        4|      Chair|  Furniture| 5000|     5|       5|\n",
            "|        5| Headphones|Electronics| 2000|     7|      10|\n",
            "+---------+-----------+-----------+-----+------+--------+\n",
            "\n",
            "Total Sales DataFrame:\n",
            "+---------+-----------+-----------+-----+------+--------+----------+\n",
            "|ProductID|ProductName|   Category|Price|SaleID|Quantity|TotalSales|\n",
            "+---------+-----------+-----------+-----+------+--------+----------+\n",
            "|        1|     Laptop|Electronics|50000|     1|       2|    100000|\n",
            "|        1|     Laptop|Electronics|50000|     4|       1|     50000|\n",
            "|        2| Smartphone|Electronics|30000|     2|       1|     30000|\n",
            "|        2| Smartphone|Electronics|30000|     6|       2|     60000|\n",
            "|        3|      Table|  Furniture|15000|     3|       3|     45000|\n",
            "|        3|      Table|  Furniture|15000|     8|       1|     15000|\n",
            "|        4|      Chair|  Furniture| 5000|     5|       5|     25000|\n",
            "|        5| Headphones|Electronics| 2000|     7|      10|     20000|\n",
            "+---------+-----------+-----------+-----+------+--------+----------+\n",
            "\n",
            "Total Sales by Product Category:\n",
            "+-----------+------------------+\n",
            "|   Category|TotalSalesCategory|\n",
            "+-----------+------------------+\n",
            "|Electronics|            260000|\n",
            "|  Furniture|             85000|\n",
            "+-----------+------------------+\n",
            "\n",
            "Sorted Products by Total Sales Value:\n",
            "+-----------+-----------------+\n",
            "|ProductName|TotalSalesProduct|\n",
            "+-----------+-----------------+\n",
            "|     Laptop|           150000|\n",
            "| Smartphone|            90000|\n",
            "|      Table|            60000|\n",
            "|      Chair|            25000|\n",
            "| Headphones|            20000|\n",
            "+-----------+-----------------+\n",
            "\n",
            "Number of Sales for Each Product:\n",
            "+-----------+----------+\n",
            "|ProductName|SalesCount|\n",
            "+-----------+----------+\n",
            "|      Chair|         1|\n",
            "|     Laptop|         2|\n",
            "|      Table|         2|\n",
            "| Smartphone|         2|\n",
            "| Headphones|         1|\n",
            "+-----------+----------+\n",
            "\n",
            "Products with Total Sales Value Greater Than ₹50,000:\n",
            "+---------+-----------+-----------+-----+------+--------+----------+\n",
            "|ProductID|ProductName|   Category|Price|SaleID|Quantity|TotalSales|\n",
            "+---------+-----------+-----------+-----+------+--------+----------+\n",
            "|        1|     Laptop|Electronics|50000|     1|       2|    100000|\n",
            "|        2| Smartphone|Electronics|30000|     6|       2|     60000|\n",
            "+---------+-----------+-----------+-----+------+--------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "  .appName(\"RDD Transformation Example\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "#Get the SparkContext from the SparkSession\n",
        "sc = spark.sparkContext\n",
        "print(\"Spark Session Created\")\n",
        "\n",
        "data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "rdd = sc.parallelize(data)\n",
        "\n",
        "\n",
        "# Print the original RDD\n",
        "print(\"Original RDD:\", rdd.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1M57lndsN8AP",
        "outputId": "b8d02562-cc9c-4f34-8c03-22ad303a8d60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark Session Created\n",
            "Original RDD: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd2 = rdd.map(lambda x: x* 2)\n",
        "\n",
        "# Print the transformed RDD\n",
        "\n",
        "print(\"RDD after map transformation (x2):\", rdd2.collect())\n",
        "\n",
        "\n",
        "rdd3 = rdd2.filter(lambda x: x % 2 == 0)\n",
        "\n",
        "# Print the filtered RDD\n",
        "\n",
        "print(\"RDD after filter transformation (even numbers):\", rdd3.collect())\n",
        "\n",
        "\n",
        "\n",
        "sentences = [\"Hello world\", \"PySpark is great\" \"RDD transformations\"]\n",
        "\n",
        "rdd4 = sc.parallelize (sentences)\n",
        "\n",
        "words_rdd = rdd4.flatMap(lambda sentence: sentence.split(\" \"))\n",
        "\n",
        "#Print the flatMapped RDD\n",
        "\n",
        "print(\"RDD after flatMap transformation (split into words):\", words_rdd.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Xg8N_LWOSjn",
        "outputId": "af0433ab-5e29-48f8-807d-d39079928df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RDD after map transformation (x2): [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
            "RDD after filter transformation (even numbers): [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
            "RDD after flatMap transformation (split into words): ['Hello', 'world', 'PySpark', 'is', 'greatRDD', 'transformations']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = rdd3.collect()\n",
        "\n",
        "print(results)\n",
        "\n",
        "\n",
        "count = rdd3.count()\n",
        "\n",
        "print(f\"Number of elements: {count}\")\n",
        "\n",
        "\n",
        "total_sum =rdd.reduce(lambda x, y: x + y)\n",
        "print(\"Total sum: (total_sum)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjCcJqUeSkVe",
        "outputId": "e573bab3-4ae3-4622-8519-e598dfbee680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
            "Number of elements: 10\n",
            "Total sum: (total_sum)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Creating a DataFrame from a dictionary\n",
        "data = {'Name': ['John', 'Emma', 'Alex'],\n",
        "        'Age': [28, 32, 25],\n",
        "        'City': ['New York', 'London', 'Paris']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Creating a DataFrame from a list of lists\n",
        "data = [['John', 28, 'New York'],\n",
        "        ['Emma', 32, 'London'],\n",
        "        ['Alex', 25, 'Paris']]\n",
        "df = pd.DataFrame(data, columns=['Name', 'Age', 'City'])"
      ],
      "metadata": {
        "id": "TpLVehiEyx-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows\n",
        "print(df.head())\n",
        "\n",
        "# Get basic information about the DataFrame\n",
        "print(df.info())\n",
        "\n",
        "# Get statistical summary of numerical columns\n",
        "print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jFaFNrAy0Yj",
        "outputId": "46639526-6ecc-49e9-8c0c-c64c0e37287b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Name  Age      City\n",
            "0  John   28  New York\n",
            "1  Emma   32    London\n",
            "2  Alex   25     Paris\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3 entries, 0 to 2\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Name    3 non-null      object\n",
            " 1   Age     3 non-null      int64 \n",
            " 2   City    3 non-null      object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 200.0+ bytes\n",
            "None\n",
            "             Age\n",
            "count   3.000000\n",
            "mean   28.333333\n",
            "std     3.511885\n",
            "min    25.000000\n",
            "25%    26.500000\n",
            "50%    28.000000\n",
            "75%    30.000000\n",
            "max    32.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a single column\n",
        "ages = df['Age']\n",
        "# display the column\n",
        "print(ages)\n",
        "\n",
        "# Select multiple columns\n",
        "subset = df[['Name', 'City']]\n",
        "print(subset)\n",
        "# Select rows based on index\n",
        "first_two = df.loc[0:1]\n",
        "print(first_two)"
      ],
      "metadata": {
        "id": "EPvhLLqjy4jd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a329118-a67b-41ba-e809-2556bd7d22eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    28\n",
            "1    32\n",
            "2    25\n",
            "Name: Age, dtype: int64\n",
            "   Name      City\n",
            "0  John  New York\n",
            "1  Emma    London\n",
            "2  Alex     Paris\n",
            "   Name  Age      City\n",
            "0  John   28  New York\n",
            "1  Emma   32    London\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename columns\n",
        "df = df.rename(columns={'Name': 'Full Name', 'City': 'Location'})\n",
        "print(df)"
      ],
      "metadata": {
        "id": "g5yYoq_Sy82B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter rows based on a condition\n",
        "young_people = df[df['Age'] < 30]\n",
        "print(young_people)\n",
        "# Multiple conditions\n",
        "young_new_yorkers = df[(df['Age'] < 30) & (df['City'] == 'New York')]\n",
        "print(young_new_yorkers)"
      ],
      "metadata": {
        "id": "MKBLbXgAzCBu",
        "outputId": "88568b65-b95a-4ff5-a193-8649c858ac85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Name  Age      City\n",
            "0  John   28  New York\n",
            "2  Alex   25     Paris\n",
            "   Name  Age      City\n",
            "0  John   28  New York\n"
          ]
        }
      ]
    }
  ]
}